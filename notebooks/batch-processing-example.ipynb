{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing Implementation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates a comprehensive batch processing implementation for data labeling of climate change-related documents. The workflow involves several key steps, including loading and preprocessing documents, extracting relevant dataset mentions, validating the extracted mentions, and finally, using an autonomous reasoning agent to ensure the quality and accuracy of the extracted data.\n",
    "\n",
    "The primary goal is to identify and categorize dataset mentions from research papers and policy documents, ensuring they are correctly classified based on naming specificity, context, and relevance. This process leverages various tools and libraries, including OpenAI, Huggingface transformers, and PyMuPDF, to automate and streamline the data labeling process.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "1. **Loading and Preprocessing**: Load documents from files or URLs and preprocess the text for extraction.\n",
    "2. **Extraction**: Use a pre-trained model for prefiltering before extracting dataset mentions from the text for efficiency.\n",
    "3. **Validation**: Validate the extracted mentions using a judge model to ensure correctness.\n",
    "4. **Reasoning**: Apply an autonomous reasoning agent to further refine and validate the extracted data.\n",
    "5. **Batch Processing**: Create and submit batch files for processing by the OpenAI API.\n",
    "6. **Results Consolidation**: Consolidate and save the results for further analysis.\n",
    "\n",
    "This aims to achieve accurate and reliable data labeling for climate change-related documents, facilitating further research and analysis in this critical field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:52:46.570139Z",
     "iopub.status.busy": "2025-02-20T06:52:46.569827Z",
     "iopub.status.idle": "2025-02-20T06:53:08.084385Z",
     "shell.execute_reply": "2025-02-20T06:53:08.082965Z",
     "shell.execute_reply.started": "2025-02-20T06:52:46.570115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# install the required packages\n",
    "!pip install --upgrade openai pymupdf transformers python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:08.239394Z",
     "iopub.status.busy": "2025-02-20T06:53:08.238847Z",
     "iopub.status.idle": "2025-02-20T06:53:09.809598Z",
     "shell.execute_reply": "2025-02-20T06:53:09.808667Z",
     "shell.execute_reply.started": "2025-02-20T06:53:08.239341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our prefiltering model from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence warnings\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:09.811300Z",
     "iopub.status.busy": "2025-02-20T06:53:09.810943Z",
     "iopub.status.idle": "2025-02-20T06:53:51.907828Z",
     "shell.execute_reply": "2025-02-20T06:53:51.906815Z",
     "shell.execute_reply.started": "2025-02-20T06:53:09.811248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "# load tokenizer from huggingface.co/models using our repository id\n",
    "data_model_id = \"ai4data-use/bert-base-uncased-data-use\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(data_model_id)\n",
    "\n",
    "# load the model from huggingface.co/models using our repository id\n",
    "classifier = pipeline(\"text-classification\", model=data_model_id, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:51.909844Z",
     "iopub.status.busy": "2025-02-20T06:53:51.908995Z",
     "iopub.status.idle": "2025-02-20T06:53:51.916232Z",
     "shell.execute_reply": "2025-02-20T06:53:51.914975Z",
     "shell.execute_reply.started": "2025-02-20T06:53:51.909812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, tokenizer, max_length=500):\n",
    "    \"\"\"\n",
    "    Split the text into chunks of max_length tokens, ensuring no chunk exceeds the model's token limit,\n",
    "    and includes special tokens properly.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be chunked.\n",
    "        tokenizer: The tokenizer to use for encoding and decoding.\n",
    "        max_length (int): The maximum length of tokens allowed in each chunk, including special tokens.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of text chunks as strings.\n",
    "    \"\"\"\n",
    "    # Reserve space for special tokens (e.g., [CLS], [SEP])\n",
    "    special_tokens_count = 2  # Adjust based on the tokenizer's special token usage\n",
    "    chunk_size = max_length - special_tokens_count\n",
    "\n",
    "    # Tokenize the text into token IDs without truncation\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    # Split the tokens into chunks\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size):\n",
    "        token_chunk = tokens[i : i + chunk_size]\n",
    "        # Add special tokens to the chunk\n",
    "        token_chunk_with_specials = (\n",
    "            [tokenizer.cls_token_id] + token_chunk + [tokenizer.sep_token_id]\n",
    "        )\n",
    "        # Decode the chunk back to text\n",
    "        chunk_text = tokenizer.decode(\n",
    "            token_chunk_with_specials, skip_special_tokens=False\n",
    "        )\n",
    "        chunks.append(chunk_text)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:51.918004Z",
     "iopub.status.busy": "2025-02-20T06:53:51.917564Z",
     "iopub.status.idle": "2025-02-20T06:53:51.939918Z",
     "shell.execute_reply": "2025-02-20T06:53:51.938700Z",
     "shell.execute_reply.started": "2025-02-20T06:53:51.917963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_extracted_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text extracted from PDFs using PyMuPDF.\n",
    "    - Reduces unnecessary whitespace and artifacts while preserving meaningful structure.\n",
    "    - Prevents unintentional removal of spaces or concatenation of words.\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace non-breaking spaces (\\xa0) with regular spaces\n",
    "    text = text.replace(\"\\xa0\", \" \")\n",
    "\n",
    "    # Remove control characters (ASCII 0-31) except line breaks\n",
    "    text = re.sub(r\"[\\x00-\\x08\\x0B-\\x1F]\", \"\", text)\n",
    "\n",
    "    # Collapse excessive newlines (more than 2) but preserve single newlines\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "\n",
    "    # Collapse multiple spaces but preserve single spaces between words\n",
    "    text = re.sub(r\"[ \\t]{2,}\", \" \", text)\n",
    "\n",
    "    # Preserve dashes at line breaks (e.g., \"address-\\nclimate\" to \"address-climate\")\n",
    "    text = re.sub(r\"([a-zA-Z])-?\\n([a-zA-Z])\", r\"\\1-\\2\", text)\n",
    "\n",
    "    # Trim leading/trailing spaces and newlines\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:51.941771Z",
     "iopub.status.busy": "2025-02-20T06:53:51.941376Z",
     "iopub.status.idle": "2025-02-20T06:53:51.962319Z",
     "shell.execute_reply": "2025-02-20T06:53:51.960714Z",
     "shell.execute_reply.started": "2025-02-20T06:53:51.941738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def should_process_page(text: str, classifier: Callable, tokenizer) -> bool:\n",
    "    \"\"\"Determine whether a page should be processed.\"\"\"\n",
    "\n",
    "    chunks = chunk_text(text, tokenizer, max_length=500)\n",
    "    return any(classifier(chunk)[0][\"label\"] != \"NO_DATA\" for chunk in chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:51.965925Z",
     "iopub.status.busy": "2025-02-20T06:53:51.965555Z",
     "iopub.status.idle": "2025-02-20T06:53:51.979483Z",
     "shell.execute_reply": "2025-02-20T06:53:51.978255Z",
     "shell.execute_reply.started": "2025-02-20T06:53:51.965893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_text_per_document(text, text_output_path, page_idx):\n",
    "    \"\"\"\n",
    "    Save cleaned text for each page to a single JSON file, appending page data.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The cleaned text for the current page.\n",
    "        text_output_path (str): The path to the text JSON file.\n",
    "        page_idx (int): The current page index.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load existing text data or create a new structure\n",
    "    if os.path.exists(text_output_path):\n",
    "        with open(text_output_path, \"r\", encoding=\"utf-8\") as existing_file:\n",
    "            text_data = json.load(existing_file)\n",
    "    else:\n",
    "        text_data = {\n",
    "            \"source\": os.path.splitext(os.path.basename(text_output_path))[0],\n",
    "            \"pages\": {},\n",
    "        }\n",
    "\n",
    "    # Add text for the current page\n",
    "    text_data[\"pages\"][str(page_idx + 1)] = text\n",
    "\n",
    "    # Save the updated text data\n",
    "    os.makedirs(os.path.dirname(text_output_path), exist_ok=True)\n",
    "    with open(text_output_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "        json.dump(text_data, text_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:51.982559Z",
     "iopub.status.busy": "2025-02-20T06:53:51.982121Z",
     "iopub.status.idle": "2025-02-20T06:53:52.001786Z",
     "shell.execute_reply": "2025-02-20T06:53:52.000416Z",
     "shell.execute_reply.started": "2025-02-20T06:53:51.982526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_texts(raw_text: str, text: str, paths: dict, page_idx: int):\n",
    "    \"\"\"Save raw and cleaned text for the page.\"\"\"\n",
    "    save_text_per_document(raw_text, paths[\"raw_text_output\"], page_idx)\n",
    "    save_text_per_document(text, paths[\"text_output\"], page_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:52.003459Z",
     "iopub.status.busy": "2025-02-20T06:53:52.003101Z",
     "iopub.status.idle": "2025-02-20T06:53:52.020589Z",
     "shell.execute_reply": "2025-02-20T06:53:52.019306Z",
     "shell.execute_reply.started": "2025-02-20T06:53:52.003428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_file_paths(base_name: str):\n",
    "    \"\"\"Generate file paths for saving outputs.\"\"\"\n",
    "    return {\n",
    "        \"text_output\": f\"output/text/{base_name}.json\",\n",
    "        \"raw_text_output\": f\"output/raw_text/{base_name}.json\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def find_best_matching_span(text, snippet, window: int = 1):\n",
    "    sents = sent_tokenize(text)\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1, 3))\n",
    "    mi_vec = tfidf.fit_transform([snippet])\n",
    "    sents_vec = tfidf.transform(sents)\n",
    "\n",
    "    mx_idx = cosine_similarity(mi_vec, sents_vec).flatten().argmax()\n",
    "    span_sents = sents[max(mx_idx - window, 0) : min(mx_idx + window + 1, len(sents))]\n",
    "\n",
    "    return {\n",
    "        \"match_idx\": mx_idx,\n",
    "        \"match_sent\": sents[mx_idx],\n",
    "        \"match_span_sents\": span_sents,\n",
    "        \"match_span\": \" \".join(span_sents),\n",
    "    }\n",
    "\n",
    "\n",
    "def find_empirical_span(\n",
    "    text: str, sentences: list, best_match_idx: int, window: int = 1\n",
    "):\n",
    "    # Define the start and end indices to include adjacent sentences for context\n",
    "    start_idx = text.index(sentences[max(best_match_idx - window, 0)])\n",
    "    last_sent = sentences[min(best_match_idx + window, len(sentences) - 1)]\n",
    "    # NOTE: This will fail if the last_sent also occurred in an earlier part of the text.\n",
    "    # SOLUTION: Start the search for last_sent from the start_idx\n",
    "    end_idx = start_idx + text[start_idx:].index(last_sent) + len(last_sent)\n",
    "\n",
    "    # Extract the final span\n",
    "    context_span = text[start_idx:end_idx]\n",
    "\n",
    "    return {\n",
    "        \"empirical_span\": context_span,  # Extracted span\n",
    "        \"start_idx\": start_idx,\n",
    "        \"end_idx\": end_idx,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_empirical_mentioned_in(\n",
    "    text, mentioned_in, window: int = 1, with_match_output: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract the most relevant span of text from the original document (`text`)\n",
    "    that matches the `mentioned_in` field. Returns the span, label, start, and end indices.\n",
    "    \"\"\"\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    match_output = find_best_matching_span(text, mentioned_in, window=window)\n",
    "    best_match_idx = match_output[\"match_idx\"]\n",
    "\n",
    "    output = find_empirical_span(text, sentences, best_match_idx, window=window)\n",
    "    output[\"empirical_mentioned_in\"] = output.pop(\"empirical_span\")\n",
    "\n",
    "    output = {\n",
    "        \"label\": \"mentioned_in\",  # Label as \"mentioned_in\"\n",
    "        **output,\n",
    "    }\n",
    "\n",
    "    if with_match_output:\n",
    "        output.update(match_output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load helper functions\n",
    "\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def consolidate_dataset(raw_text: str, data: dict):\n",
    "    text = raw_text\n",
    "    page_data = {\"dataset_used\": data.get(\"dataset_used\", False), \"data_mentions\": []}\n",
    "\n",
    "    G = nx.Graph()\n",
    "    sents = sent_tokenize(text)\n",
    "    _datasets = []\n",
    "\n",
    "    for ds in data.get(\"dataset\", []):\n",
    "        mentioned_in = ds.pop(\"mentioned_in\") or \"\"\n",
    "\n",
    "        try:\n",
    "            mi = find_best_matching_span(mentioned_in, ds[\"raw_name\"], window=0)\n",
    "            mi = mi[\"match_span\"]\n",
    "            match_output = find_best_matching_span(text, mi, window=1)\n",
    "        except ValueError:\n",
    "            # Likely that the `mentioned_in` is not found in the text or not correct.\n",
    "            # We try expanding the search to the entire text.\n",
    "            match_output = find_best_matching_span(text, ds[\"raw_name\"], window=1)\n",
    "\n",
    "        ds[\"sent_spans\"] = match_output[\"match_span_sents\"]\n",
    "        sents_idx = sorted([sents.index(s) for s in ds[\"sent_spans\"]])\n",
    "        ds[\"sent\"] = match_output[\"match_sent\"]\n",
    "        ds[\"sent_idx\"] = sents_idx\n",
    "\n",
    "        G.add_edges_from(zip(sents_idx[:-1], sents_idx[1:]))\n",
    "        _datasets.append(ds)\n",
    "\n",
    "    _datasets = sorted(_datasets, key=lambda x: x[\"sent_idx\"][0])\n",
    "\n",
    "    # The connected components in the graphs form the `mentioned_in`s.\n",
    "    mentioned_ins = sorted(\n",
    "        [sorted(x) for x in nx.connected_components(G)], key=lambda x: x[0]\n",
    "    )\n",
    "    updated_mentions = []\n",
    "\n",
    "    for midx in mentioned_ins:\n",
    "        _mi = {\"mentioned_in\": \" \".join([sents[i] for i in midx]), \"datasets\": []}\n",
    "\n",
    "        for ds in _datasets:\n",
    "            ds = deepcopy(ds)\n",
    "            if ds[\"sent_idx\"][0] in midx:\n",
    "                ds.pop(\"sent_idx\")\n",
    "                ds.pop(\"sent_spans\")\n",
    "                _mi[\"datasets\"].append(ds)\n",
    "\n",
    "        updated_mentions.append(_mi)\n",
    "\n",
    "    page_data[\"data_mentions\"] = updated_mentions\n",
    "\n",
    "    return page_data\n",
    "\n",
    "\n",
    "def save_output_per_document(raw_text, data, output_path, page_idx):\n",
    "    \"\"\"\n",
    "    Save output data to a JSON file per document, appending new page data.\n",
    "\n",
    "    Parameters:\n",
    "        data (LabelledResponseFormat): The data to save, in the validated format.\n",
    "        output_path (str): The output path for the document-wide JSON file.\n",
    "        page_idx (int): The current page index being processed.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Restructure and consolidate dataset if possible\n",
    "    page_data = consolidate_dataset(raw_text, data)\n",
    "\n",
    "    # Initialize the new page's data structure\n",
    "    page_data = {\"page\": page_idx + 1, **page_data}\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(output_path):\n",
    "        with open(output_path, \"r\", encoding=\"utf-8\") as existing_file:\n",
    "            document_data = json.load(existing_file)\n",
    "    else:\n",
    "        # Create a new JSON structure\n",
    "        document_data = {\n",
    "            \"source\": os.path.splitext(os.path.basename(output_path))[0],\n",
    "            \"pages\": [],\n",
    "        }\n",
    "\n",
    "    # Append the new page data\n",
    "    document_data[\"pages\"].append(page_data)\n",
    "\n",
    "    # Save the updated document data back to the file\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        json.dump(document_data, output_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:52.022245Z",
     "iopub.status.busy": "2025-02-20T06:53:52.021949Z",
     "iopub.status.idle": "2025-02-20T06:53:52.040408Z",
     "shell.execute_reply": "2025-02-20T06:53:52.039020Z",
     "shell.execute_reply.started": "2025-02-20T06:53:52.022220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from openai.lib._parsing._completions import type_to_response_format_param\n",
    "\n",
    "\n",
    "def build_payload(page, prompt, response_format=None):\n",
    "    \"\"\"\n",
    "    Constructs a properly formatted OpenAI API payload for batch processing.\n",
    "\n",
    "    Args:\n",
    "        page (str): Text content of the page.\n",
    "        prompt (str): System prompt for guidance.\n",
    "        response_format (LabelledResponseFormat): Response schema from `StructuredOutputs`.\n",
    "\n",
    "    Returns:\n",
    "        dict: JSON payload formatted for OpenAI batch API.\n",
    "    \"\"\"\n",
    "    default_kwargs = dict(\n",
    "        model=MODEL,\n",
    "        temperature=0,\n",
    "        max_tokens=16383,  # `max_completion_tokens` isn't a valid OpenAI param\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    # Ensure response_format uses JSON schema from LabelledResponseFormat\n",
    "    payload = dict(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": prompt}]},\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": page}]},\n",
    "        ],\n",
    "        # response_format={\"type\": \"json_schema\", \"schema\": response_format.model_json_schema()},  # to_strict_json_schema\n",
    "        response_format=type_to_response_format_param(response_format)\n",
    "        if response_format\n",
    "        else {\"type\": \"text\"},\n",
    "        **default_kwargs,\n",
    "    )\n",
    "\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:52.042173Z",
     "iopub.status.busy": "2025-02-20T06:53:52.041858Z",
     "iopub.status.idle": "2025-02-20T06:53:52.166396Z",
     "shell.execute_reply": "2025-02-20T06:53:52.165398Z",
     "shell.execute_reply.started": "2025-02-20T06:53:52.042147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def load_doc(fname_or_url: str, n_pages: int = 1) -> list:\n",
    "    \"\"\"\n",
    "    Loads a PDF document from a file or URL and extracts content from it.\n",
    "\n",
    "    Args:\n",
    "        fname_or_url (str): The path to the PDF file or a URL where the file can be downloaded.\n",
    "        n_pages (int, optional): The number of pages to extract. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the extracted text and page indices.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the number of pages is not greater than 0.\n",
    "        Exception: If the PDF file fails to download from the specified URL or if there's an issue loading the document.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate that the number of pages is greater than 0\n",
    "    assert n_pages > 0, \"The number of pages must be greater than 0.\"\n",
    "\n",
    "    def _load_doc(fname: str) -> list:\n",
    "        \"\"\"\n",
    "        Creates content from two successive pages.\n",
    "\n",
    "        Args:\n",
    "            fname (str): The path to the PDF file.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of dictionaries containing the extracted text and page indices.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize an empty list to store the contents\n",
    "        contents = []\n",
    "\n",
    "        # Open the PDF document\n",
    "        doc = pymupdf.open(fname)\n",
    "\n",
    "        # Iterate over the pages, skipping the last n_pages - 1 pages\n",
    "        for page_idx in range(len(doc) - (n_pages - 1)):\n",
    "            # Extract text from each of the next n_pages pages and store it as a dictionary\n",
    "            contents.append(\n",
    "                dict(\n",
    "                    text=\"\\n\\n\".join(\n",
    "                        [doc[page_idx + i].get_text() for i in range(n_pages)]\n",
    "                    ),\n",
    "                    pages=[page_idx + i for i in range(n_pages)],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Validate that all pages were loaded successfully\n",
    "        assert len(doc) - (n_pages - 1) == len(contents), \"Failed to load all pages.\"\n",
    "\n",
    "        return contents\n",
    "\n",
    "    # Check if the file or URL starts with 'http:' or 'https:'\n",
    "    if fname_or_url.startswith((\"http:\", \"https:\")):\n",
    "        # Download the PDF file from the specified URL\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".pdf\") as temp_pdf:\n",
    "            response = requests.get(fname_or_url, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                # Write the downloaded data to the temporary file\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    temp_pdf.write(chunk)\n",
    "                # Seek back to the beginning of the file and return the loaded document\n",
    "                temp_pdf.seek(0)\n",
    "                return _load_doc(temp_pdf.name)\n",
    "            else:\n",
    "                # Raise an exception if there's an issue with the download or loading the document\n",
    "                raise Exception(\n",
    "                    f\"Failed to download PDF, status code: {response.status_code}\"\n",
    "                )\n",
    "\n",
    "    else:\n",
    "        # If it's not a URL, simply load the document from the specified file path\n",
    "        return _load_doc(fname_or_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:52.167686Z",
     "iopub.status.busy": "2025-02-20T06:53:52.167409Z",
     "iopub.status.idle": "2025-02-20T06:53:52.181592Z",
     "shell.execute_reply": "2025-02-20T06:53:52.180176Z",
     "shell.execute_reply.started": "2025-02-20T06:53:52.167663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "# Define Enums for categorical fields\n",
    "class Context(str, Enum):\n",
    "    background = \"background\"\n",
    "    supporting = \"supporting\"\n",
    "    primary = \"primary\"\n",
    "\n",
    "\n",
    "class Specificity(str, Enum):\n",
    "    properly_named = \"properly_named\"\n",
    "    descriptive_but_unnamed = \"descriptive_but_unnamed\"\n",
    "    vague_generic = \"vague_generic\"\n",
    "\n",
    "\n",
    "class Relevance(str, Enum):\n",
    "    directly_relevant = \"directly_relevant\"\n",
    "    indirectly_relevant = \"indirectly_relevant\"\n",
    "    not_relevant = \"not_relevant\"\n",
    "\n",
    "\n",
    "class DatasetEntry(BaseModel):\n",
    "    raw_name: Optional[str] = Field(\n",
    "        ..., description=\"The exact dataset name as it appears in the text.\"\n",
    "    )\n",
    "    harmonized_name: Optional[str] = Field(\n",
    "        None, description=\"The standardized or full name of the dataset.\"\n",
    "    )\n",
    "    acronym: Optional[str] = Field(\n",
    "        None, description=\"The short name or acronym associated with the dataset.\"\n",
    "    )\n",
    "    context: Context\n",
    "    specificity: Specificity\n",
    "    relevance: Relevance\n",
    "    mentioned_in: Optional[str] = Field(\n",
    "        None, description=\"The exact text excerpt where the dataset is mentioned.\"\n",
    "    )\n",
    "    producer: Optional[str] = Field(\n",
    "        None, description=\"The organization responsible for producing the dataset.\"\n",
    "    )\n",
    "    data_type: Optional[str] = Field(\n",
    "        None, description=\"The type of data represented by the dataset.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class LabelledResponseFormat(BaseModel):\n",
    "    dataset: List[DatasetEntry] = Field(\n",
    "        ..., description=\"A list of datasets mentioned in the paper.\"\n",
    "    )\n",
    "    dataset_used: bool = Field(\n",
    "        ..., description=\"A boolean indicating if a dataset is used in the paper.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:52.183250Z",
     "iopub.status.busy": "2025-02-20T06:53:52.182859Z",
     "iopub.status.idle": "2025-02-20T06:53:52.204860Z",
     "shell.execute_reply": "2025-02-20T06:53:52.203757Z",
     "shell.execute_reply.started": "2025-02-20T06:53:52.183203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_USE_TASK_PROMPT = \"\"\"You are an expert in extracting and categorizing dataset mentions from research papers and policy documents. Your task is to **identify and extract all valid dataset mentions**, ensuring they are correctly classified based on naming specificity, context, and relevance.\n",
    "\n",
    "### **What Qualifies as a Dataset?**\n",
    "A dataset is a structured collection of data used for empirical research, analysis, or policy-making. Examples include:\n",
    "- **Surveys & Census Data** (e.g., LSMS, DHS, national census records)\n",
    "- **Indicators & Indexes** (e.g., HDI, GFSI, WDI, ND-GAIN, EPI)\n",
    "- **Geospatial & Environmental Data** (e.g., OpenStreetMap, Sentinel-2 imagery)\n",
    "- **Economic & Trade Data** (e.g., UN Comtrade, Balance of Payments Statistics)\n",
    "- **Health & Public Safety Data** (e.g., epidemiological surveillance, crime reports)\n",
    "- **Time-Series & Energy Data** (e.g., climate projections, electricity demand records)\n",
    "- **Transport & Mobility Data** (e.g., road accident statistics, smart city traffic flow)\n",
    "- **Other emerging dataset types** as identified in the text.\n",
    "\n",
    "**Important:**  \n",
    "If the dataset does not fit into the examples above, infer the **most appropriate category** from the context and **create a new `\"data_type\"` if necessary**.\n",
    "\n",
    "### **What Should NOT Be Extracted?**\n",
    "Do **not** extract mentions that do not clearly refer to a dataset, including, but not limited to:\n",
    "1. **Organizations & Institutions** (e.g., WHO, IMF, UNDP, \"World Bank data\" unless it explicitly refers to a dataset)\n",
    "2. **Reports & Policy Documents** (e.g., \"Fiscal Monitor by the IMF\", \"IEA Energy Report\"; only extract if the dataset itself is referenced)\n",
    "3. **Generic Mentions of Data** (e.g., \"various sources\", \"survey results from multiple institutions\")\n",
    "4. **Economic Models & Policy Frameworks** (e.g., \"GDP growth projections\", \"macroeconomic forecasts\")\n",
    "5. **Legislation & Agreements** (e.g., \"Paris Agreement\", \"General Data Protection Regulation\")\n",
    "\n",
    "### **Rules for Extraction**\n",
    "1. **Extract All Structured Data Mentions**\n",
    "   - If the dataset is explicitly named (e.g., \"Global Fishing Watch\"), label it as `\"properly_named\"`.\n",
    "   - If the dataset is described but not explicitly named (e.g., \"electricity usage data from Albania\"), label it as `\"descriptive_but_unnamed\"`.\n",
    "   - If the dataset mention is too generic (e.g., \"electricity usage data\"), label it as `\"vague_generic\"`.\n",
    "\n",
    "2. **Ensure `\"data_type\"` Is Always Assigned**\n",
    "   - **Use an existing category if applicable.**\n",
    "   - **If no suitable category exists, create a new `\"data_type\"` based on context.**\n",
    "\n",
    "3. **Classify `\"context\"` Correctly**\n",
    "   - `\"primary\"`: The dataset is used for direct analysis in the document.\n",
    "   - `\"supporting\"`: The dataset is referenced to validate or compare findings.\n",
    "   - `\"background\"`: The dataset is mentioned as general context or prior research.\n",
    "\n",
    "   **Examples:**\n",
    "   - `\"The LSMS-ISA data is analyzed to assess the impact of agricultural practices on productivity.\"` → `\"primary\"`\n",
    "   - `\"Our results align with previous studies that used LSMS-ISA.\"` → `\"supporting\"`\n",
    "   - `\"LSMS-ISA is widely recognized as a reliable data source for agricultural research.\"` → `\"background\"`\n",
    "\n",
    "4. **Capture Full Sentence Context**\n",
    "   - The `\"mentioned_in\"` field must always include the **full sentence** where the dataset is referenced.\n",
    "   - If a dataset is mistakenly extracted from an unrelated sentence, correct it.\n",
    "\n",
    "### **Extraction Schema**\n",
    "Each extracted dataset should have the following fields:\n",
    "- `raw_name`: Exact dataset name from the text (**no paraphrasing**).\n",
    "- `harmonized_name`: If properly named, use directly; if referenced in multiple ways, standardize using the most precise form in the text, otherwise, set this to None.\n",
    "- `acronym`: Extract if explicitly mentioned.\n",
    "- `mentioned_in`: **Full sentence** where the dataset appears (**no paraphrasing**).\n",
    "- `context`: **primary / supporting / background**\n",
    "- `specificity`: **properly_named / descriptive_but_unnamed / vague_generic**\n",
    "- `relevance`: **directly_relevant / indirectly_relevant / not_relevant**\n",
    "- `producer`: **Extract only if explicitly mentioned; otherwise, set to `None`.**\n",
    "- `data_type`: **Assign based on existing categories, but create new ones if necessary.**\n",
    "\n",
    "### **Handling New or Unlisted Data Types**\n",
    "- If a dataset does not fit into existing categories, **infer an appropriate name** for its `\"data_type\"` based on context.\n",
    "- Use a **general but informative label** for new data types (e.g., `\"Climate Risk Data\"`, `\"Social Media Analytics\"`).\n",
    "\n",
    "### **Important: Do NOT Skip Unnamed Datasets**\n",
    "If a dataset is described but lacks a proper name, extract it under `\"descriptive_but_unnamed\"` or `\"vague_generic\"`, which ever is appropriate.\n",
    "If `\"producer\"` is not mentioned, set it to `None` rather than inferring.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Batches for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:52.206336Z",
     "iopub.status.busy": "2025-02-20T06:53:52.206017Z",
     "iopub.status.idle": "2025-02-20T06:53:52.232497Z",
     "shell.execute_reply": "2025-02-20T06:53:52.231246Z",
     "shell.execute_reply.started": "2025-02-20T06:53:52.206298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory for batch files & results\n",
    "BATCH_DIR = \"./openai-batchfiles/extraction\"  # Directory for batch files\n",
    "OUTPUT_DIR = \"./extraction_outputs\"  # Directory for OpenAI API responses\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "# Ensure output folders exist\n",
    "os.makedirs(BATCH_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:52.234218Z",
     "iopub.status.busy": "2025-02-20T06:53:52.233817Z",
     "iopub.status.idle": "2025-02-20T06:53:52.252091Z",
     "shell.execute_reply": "2025-02-20T06:53:52.250842Z",
     "shell.execute_reply.started": "2025-02-20T06:53:52.234181Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Process Each PDF into Its Own Batch\n",
    "def process_pdf_into_batch(pdf_fname, prompt, response_format, classifier, tokenizer):\n",
    "    \"\"\"Processes a single PDF file into an OpenAI batch file.\"\"\"\n",
    "\n",
    "    file_basename = os.path.basename(pdf_fname).replace(\".pdf\", \"\")\n",
    "    batch_fname = os.path.join(BATCH_DIR, f\"batch-{file_basename}.jsonl\")\n",
    "\n",
    "    paths = generate_file_paths(file_basename)\n",
    "\n",
    "    if os.path.exists(batch_fname):\n",
    "        print(f\"Batch file {batch_fname} already exists. Skipping.\")\n",
    "        return batch_fname  # Skip if already processed\n",
    "\n",
    "    pages = load_doc(pdf_fname, n_pages=1)\n",
    "\n",
    "    seen_custom_ids = set()\n",
    "    with open(batch_fname, \"a+\") as f:\n",
    "        for page in tqdm(pages, desc=f\"Processing {file_basename}\"):\n",
    "            raw_text = page.get(\"text\")\n",
    "            page_text = clean_extracted_text(raw_text)\n",
    "            page_num = page.get(\"pages\")[0]\n",
    "            save_texts(raw_text, page_text, paths, page_num)\n",
    "\n",
    "            if not page_text or not should_process_page(\n",
    "                page_text, classifier, tokenizer\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            custom_id = f\"{file_basename}-page-{page_num}\"\n",
    "            if custom_id in seen_custom_ids:\n",
    "                continue\n",
    "            seen_custom_ids.add(custom_id)\n",
    "\n",
    "            batch_entry = dict(\n",
    "                custom_id=custom_id,\n",
    "                method=\"POST\",\n",
    "                url=\"/v1/chat/completions\",\n",
    "                body=build_payload(page_text, prompt, response_format),\n",
    "            )\n",
    "\n",
    "            f.write(json.dumps(batch_entry) + \"\\n\")\n",
    "\n",
    "    print(f\"Created batch file: {batch_fname}\")\n",
    "    return batch_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to create input directory and put your pdf files there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:52.253635Z",
     "iopub.status.busy": "2025-02-20T06:53:52.253312Z",
     "iopub.status.idle": "2025-02-20T06:53:52.276890Z",
     "shell.execute_reply": "2025-02-20T06:53:52.275820Z",
     "shell.execute_reply.started": "2025-02-20T06:53:52.253608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "INPUT_DIRECTORY = \"./input/\"\n",
    "os.makedirs(INPUT_DIRECTORY, exist_ok=True)\n",
    "\n",
    "PDF_FILES = glob.glob(INPUT_DIRECTORY + \"/*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:52.278664Z",
     "iopub.status.busy": "2025-02-20T06:53:52.278308Z",
     "iopub.status.idle": "2025-02-20T06:53:52.295667Z",
     "shell.execute_reply": "2025-02-20T06:53:52.294441Z",
     "shell.execute_reply.started": "2025-02-20T06:53:52.278623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PDF_FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:53:52.297371Z",
     "iopub.status.busy": "2025-02-20T06:53:52.296954Z",
     "iopub.status.idle": "2025-02-20T06:55:07.357847Z",
     "shell.execute_reply": "2025-02-20T06:55:07.356630Z",
     "shell.execute_reply.started": "2025-02-20T06:53:52.297324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "prompt = DATA_USE_TASK_PROMPT\n",
    "response_format = LabelledResponseFormat\n",
    "# loop through each PDF file and process it into a batch\n",
    "for pdf_fname in PDF_FILES:\n",
    "    _ = process_pdf_into_batch(\n",
    "        pdf_fname, prompt, response_format, classifier, tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:07.515531Z",
     "iopub.status.busy": "2025-02-20T06:55:07.515119Z",
     "iopub.status.idle": "2025-02-20T06:55:07.527389Z",
     "shell.execute_reply": "2025-02-20T06:55:07.526001Z",
     "shell.execute_reply.started": "2025-02-20T06:55:07.515479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directories\n",
    "BATCH_DIR = \"./openai-batchfiles/extraction\"\n",
    "MERGED_BATCH_DIR = \"./batches\"  # Where we save the consolidated batch files\n",
    "MAX_REQUESTS_PER_BATCH = 15  # Number of requests per batch\n",
    "\n",
    "# Ensure merged batch directory exists\n",
    "os.makedirs(MERGED_BATCH_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def consolidate_batches(\n",
    "    batch_dir=BATCH_DIR, batch_size=MAX_REQUESTS_PER_BATCH, process=\"extraction\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Consolidates JSONL batch files into larger ones while preserving structure.\n",
    "\n",
    "    Args:\n",
    "        batch_dir (str): Directory containing batch files.\n",
    "        batch_size (int): Max requests per merged batch file.\n",
    "\n",
    "    Returns:\n",
    "        list: List of saved merged batch file paths.\n",
    "    \"\"\"\n",
    "    batch_files = [\n",
    "        os.path.join(batch_dir, f)\n",
    "        for f in os.listdir(batch_dir)\n",
    "        if f.endswith(\".jsonl\")\n",
    "    ]\n",
    "    batch_files.sort()\n",
    "\n",
    "    merged_batches = []\n",
    "    current_batch = []\n",
    "    batch_count = 1\n",
    "    if process:\n",
    "        os.makedirs(os.path.join(MERGED_BATCH_DIR, process), exist_ok=True)\n",
    "    for batch_file in batch_files:\n",
    "        try:\n",
    "            with open(batch_file, \"r\") as f:\n",
    "                batch_data = [\n",
    "                    json.loads(line) for line in f if line.strip()\n",
    "                ]  # Skip empty lines\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Skipping {batch_file} due to JSON decoding error: {e}\")\n",
    "            continue  # Skip corrupt files\n",
    "\n",
    "        for entry in batch_data:\n",
    "            current_batch.append(entry)\n",
    "\n",
    "            # If batch reaches the specified size, save and reset\n",
    "            if len(current_batch) >= batch_size:\n",
    "                merged_batch_file = os.path.join(\n",
    "                    MERGED_BATCH_DIR, f\"{process}/merged-batch-{batch_count}.jsonl\"\n",
    "                )\n",
    "                with open(merged_batch_file, \"w\") as f_out:\n",
    "                    f_out.write(\n",
    "                        \"\\n\".join(json.dumps(item) for item in current_batch) + \"\\n\"\n",
    "                    )\n",
    "\n",
    "                merged_batches.append(merged_batch_file)\n",
    "                print(f\"Created merged batch: {merged_batch_file}\")\n",
    "\n",
    "                # Reset for next batch\n",
    "                current_batch = []\n",
    "                batch_count += 1\n",
    "\n",
    "    # Save any remaining batch data\n",
    "    if current_batch:\n",
    "        merged_batch_file = os.path.join(\n",
    "            MERGED_BATCH_DIR, f\"{process}/merged-batch-{batch_count}.jsonl\"\n",
    "        )\n",
    "        with open(merged_batch_file, \"w\") as f_out:\n",
    "            f_out.write(\"\\n\".join(json.dumps(item) for item in current_batch) + \"\\n\")\n",
    "\n",
    "        merged_batches.append(merged_batch_file)\n",
    "        print(f\"Created merged batch: {merged_batch_file}\")\n",
    "\n",
    "    return merged_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:07.528973Z",
     "iopub.status.busy": "2025-02-20T06:55:07.528630Z",
     "iopub.status.idle": "2025-02-20T06:55:07.557882Z",
     "shell.execute_reply": "2025-02-20T06:55:07.556421Z",
     "shell.execute_reply.started": "2025-02-20T06:55:07.528932Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "merged_batches = consolidate_batches(\n",
    "    batch_dir=BATCH_DIR, batch_size=15, process=\"extraction\"\n",
    ")  # change your batch_size here (50K max for OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:07.564264Z",
     "iopub.status.busy": "2025-02-20T06:55:07.563925Z",
     "iopub.status.idle": "2025-02-20T06:55:07.570549Z",
     "shell.execute_reply": "2025-02-20T06:55:07.569595Z",
     "shell.execute_reply.started": "2025-02-20T06:55:07.564236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "merged_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting JSONL Batches to OpenAI\n",
    "\n",
    "After creating and merging the JSONL batches, the next step is to submit these batches to the OpenAI API for processing. The following code demonstrates how to upload and submit the merged batch files to OpenAI:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:07.573654Z",
     "iopub.status.busy": "2025-02-20T06:55:07.573359Z",
     "iopub.status.idle": "2025-02-20T06:55:07.588246Z",
     "shell.execute_reply": "2025-02-20T06:55:07.587240Z",
     "shell.execute_reply.started": "2025-02-20T06:55:07.573628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def submit_batches_to_openai(batch_filenames):\n",
    "    \"\"\"\n",
    "    Uploads and submits merged batch files to OpenAI.\n",
    "\n",
    "    Args:\n",
    "        batch_filenames (list): List of merged batch file paths.\n",
    "    \"\"\"\n",
    "    # batch_input_files = []\n",
    "    openai_batches = []\n",
    "\n",
    "    for batch_fname in tqdm(batch_filenames, desc=\"Uploading merged batch files\"):\n",
    "        try:\n",
    "            with open(batch_fname, \"rb\") as file:\n",
    "                uploaded_file_id = client.files.create(file=file, purpose=\"batch\").id\n",
    "\n",
    "            # Submit batch job\n",
    "            batch = client.batches.create(\n",
    "                input_file_id=uploaded_file_id,\n",
    "                endpoint=\"/v1/chat/completions\",\n",
    "                completion_window=\"24h\",\n",
    "                metadata={\"description\": f\"Merged batch processing: {batch_fname}\"},\n",
    "            )\n",
    "\n",
    "            openai_batches.append(batch)\n",
    "            print(f\"Submitted batch: {batch.id}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {batch_fname}: {e}\")\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    return openai_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:07.589567Z",
     "iopub.status.busy": "2025-02-20T06:55:07.589248Z",
     "iopub.status.idle": "2025-02-20T06:55:07.607813Z",
     "shell.execute_reply": "2025-02-20T06:55:07.606652Z",
     "shell.execute_reply.started": "2025-02-20T06:55:07.589538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "openai_batches = submit_batches_to_openai(merged_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will take a while for the batch process to be completed\n",
    "\n",
    "You can continue checking until the status is 'completed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:08.544145Z",
     "iopub.status.busy": "2025-02-20T06:55:08.542927Z",
     "iopub.status.idle": "2025-02-20T06:55:08.550359Z",
     "shell.execute_reply": "2025-02-20T06:55:08.548871Z",
     "shell.execute_reply.started": "2025-02-20T06:55:08.544108Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Helper function to list all submitted batches, their statuses.\n",
    "def list_batches():\n",
    "    \"\"\"\n",
    "    Lists all submitted batches along with their statuses.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        batches = client.batches.list()\n",
    "        print(\"All Batch Jobs:\")\n",
    "        for batch in batches:\n",
    "            print(\n",
    "                f\"Batch ID: {batch.id}, Status: {batch.status}, Created At: {batch.created_at}\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing batches: {e}\")\n",
    "\n",
    "\n",
    "# list_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in openai_batches:\n",
    "    print(f\"Batch ID: {batch.id}, Status: {batch.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:08.552515Z",
     "iopub.status.busy": "2025-02-20T06:55:08.551913Z",
     "iopub.status.idle": "2025-02-20T06:55:09.452772Z",
     "shell.execute_reply": "2025-02-20T06:55:09.451682Z",
     "shell.execute_reply.started": "2025-02-20T06:55:08.552397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# once completed we can download the results\n",
    "# for demo purposes, the following batch_ids are completed and ready for download\n",
    "\n",
    "batch_ids = [\n",
    "    \"batch_67b4adcc7a248190b5c339d0fba3a727\",\n",
    "    \"batch_67b4adc9d4c88190ab4eabdf6578552e\",\n",
    "]\n",
    "\n",
    "\n",
    "def retrieve_batch_results(batch_ids, process=\"extraction\"):\n",
    "    if process:\n",
    "        os.makedirs(f\"./batches/{process}\", exist_ok=True)\n",
    "    for batch_id in batch_ids:\n",
    "        batch_details = client.batches.retrieve(batch_id)\n",
    "        if batch_details.status == \"completed\":\n",
    "            result = client.files.content(batch_details.output_file_id).content\n",
    "            results_file = f\"./batches/{process}/results-{batch_id}.jsonl\"\n",
    "            with open(results_file, \"wb\") as file:\n",
    "                file.write(result)\n",
    "            print(f\"saved results to {results_file}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "_ = retrieve_batch_results(batch_ids, process=\"extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:09.454122Z",
     "iopub.status.busy": "2025-02-20T06:55:09.453842Z",
     "iopub.status.idle": "2025-02-20T06:55:09.459854Z",
     "shell.execute_reply": "2025-02-20T06:55:09.458447Z",
     "shell.execute_reply.started": "2025-02-20T06:55:09.454098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_save_outputs(batch_files):\n",
    "    payload = []\n",
    "    for batch_file in batch_files:\n",
    "        # Loading data from saved file\n",
    "\n",
    "        with open(batch_file, \"r\") as file:\n",
    "            for line in file:\n",
    "                # Parsing the JSON string into a dict and appending to the list of results\n",
    "                json_object = json.loads(line.strip())\n",
    "                payload.append(json_object)\n",
    "\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:09.461338Z",
     "iopub.status.busy": "2025-02-20T06:55:09.461016Z",
     "iopub.status.idle": "2025-02-20T06:55:09.480350Z",
     "shell.execute_reply": "2025-02-20T06:55:09.478971Z",
     "shell.execute_reply.started": "2025-02-20T06:55:09.461311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "batch_files = glob.glob(\"./batches/extraction/results-*.jsonl\")\n",
    "payload = load_and_save_outputs(batch_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:09.482031Z",
     "iopub.status.busy": "2025-02-20T06:55:09.481727Z",
     "iopub.status.idle": "2025-02-20T06:55:09.501769Z",
     "shell.execute_reply": "2025-02-20T06:55:09.500524Z",
     "shell.execute_reply.started": "2025-02-20T06:55:09.482004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "extraction_path = \"./extraction_outputs/extraction\"\n",
    "raw_text_path = \"./output/raw_text\"\n",
    "os.makedirs(extraction_path, exist_ok=True)\n",
    "os.makedirs(raw_text_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def map_and_save_output(payload, extraction_path, raw_text_path):\n",
    "    for res in payload:\n",
    "        fname_origin = res[\"custom_id\"].split(\"-page-\")[0]\n",
    "        page = int(res[\"custom_id\"].split(\"-page-\")[-1])\n",
    "        page_str = str(page + 1)\n",
    "\n",
    "        content = json.loads(\n",
    "            res[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        )\n",
    "\n",
    "        extraction_resfname = extraction_path + f\"/{fname_origin}.json\"\n",
    "        if content.get(\"dataset\") != []:\n",
    "            with open(\n",
    "                raw_text_path + f\"/{fname_origin}.json\", \"r\", encoding=\"utf-8\"\n",
    "            ) as raw_txt:\n",
    "                raw_text = json.load(raw_txt).get(\"pages\").get(page_str)\n",
    "            save_output_per_document(raw_text, content, extraction_resfname, page)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:09.503348Z",
     "iopub.status.busy": "2025-02-20T06:55:09.502940Z",
     "iopub.status.idle": "2025-02-20T06:55:09.907388Z",
     "shell.execute_reply": "2025-02-20T06:55:09.906293Z",
     "shell.execute_reply.started": "2025-02-20T06:55:09.503312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_ = map_and_save_output(payload, extraction_path, raw_text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:09.909229Z",
     "iopub.status.busy": "2025-02-20T06:55:09.908840Z",
     "iopub.status.idle": "2025-02-20T06:55:09.915242Z",
     "shell.execute_reply": "2025-02-20T06:55:09.914047Z",
     "shell.execute_reply.started": "2025-02-20T06:55:09.909193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# you can use the following function to inspect the json file\n",
    "def inspect_json(json_file):\n",
    "    try:\n",
    "        with open(json_file, \"r\") as f:\n",
    "            results = [json.loads(line) for line in f]\n",
    "        return results\n",
    "    except Exception:\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as fn:\n",
    "            return json.load(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect and check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:09.917132Z",
     "iopub.status.busy": "2025-02-20T06:55:09.916767Z",
     "iopub.status.idle": "2025-02-20T06:55:09.942200Z",
     "shell.execute_reply": "2025-02-20T06:55:09.941026Z",
     "shell.execute_reply.started": "2025-02-20T06:55:09.917102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "json_file = (\n",
    "    \"./extraction_outputs/extraction/06c998e896785ab8b6d6caa4a8beb2f505c375a5.json\"\n",
    ")\n",
    "inspect_json(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-as-a-Judge for Quality Assessment\n",
    "\n",
    "After extracting dataset mentions, we validate the output using an LLM-as-a-judge pipeline. This involves:\n",
    "\n",
    "1. **Validation Criteria**: Assess dataset mentions as valid, invalid, or needing clarification.\n",
    "2. **Consistency Check**: Ensure consistent validity unless context changes.\n",
    "3. **Context-Aware Inference**: Extract missing details from the `mentioned_in` field.\n",
    "4. **Data Type Classification**: Infer appropriate data types from context.\n",
    "5. **Producer Identification**: Extract explicitly mentioned producers; otherwise, set to `None`.\n",
    "\n",
    "Validation Criteria\n",
    "A dataset is **valid** if:\n",
    "- Structured and systematically collected.\n",
    "- Reproducible, consisting of collected records.\n",
    "\n",
    "**Always Valid Datasets**:\n",
    "- Government statistical and geospatial datasets.\n",
    "- Official surveys, administrative records, economic transaction data, and scientific research datasets.\n",
    "\n",
    "**Invalid Datasets**:\n",
    "- Derived indicators or computational constructs.\n",
    "- Standalone statistical metrics without clear underlying data.\n",
    "- General organizations, reports, or methodologies.\n",
    "\n",
    "**Uncertain Cases**:\n",
    "- Vaguely named but potentially valid: `\"Potentially valid—needs dataset name confirmation.\"`\n",
    "- Too generic: `\"Needs clarification—dataset name is too generic.\"`\n",
    "\n",
    "Key Validation Rules\n",
    "1. **Consistency Check**: Maintain validity unless context changes.\n",
    "2. **Context-Aware Inference**: Extract missing details from the `mentioned_in` field.\n",
    "3. **Data Type Classification**: Infer appropriate data types from context.\n",
    "4. **Producer Identification**: Extract explicitly mentioned producers; otherwise, set to `None`.\n",
    "\n",
    "Each dataset assessment must conform to the `JudgeResponseFormat` schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:09.943919Z",
     "iopub.status.busy": "2025-02-20T06:55:09.943567Z",
     "iopub.status.idle": "2025-02-20T06:55:09.965692Z",
     "shell.execute_reply": "2025-02-20T06:55:09.964201Z",
     "shell.execute_reply.started": "2025-02-20T06:55:09.943889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a pydantic model for the judge response\n",
    "from pydantic import model_validator\n",
    "\n",
    "\n",
    "class JudgeDatasetEntry(BaseModel):\n",
    "    raw_name: Optional[str] = Field(\n",
    "        ..., description=\"The exact dataset name as it appears in the text.\"\n",
    "    )\n",
    "    harmonized_name: Optional[str] = Field(\n",
    "        None, description=\"The standardized or full name of the dataset.\"\n",
    "    )\n",
    "    acronym: Optional[str] = Field(\n",
    "        None, description=\"The short name or acronym associated with the dataset.\"\n",
    "    )\n",
    "    context: Context\n",
    "    specificity: Specificity\n",
    "    relevance: Relevance\n",
    "    producer: Optional[str] = Field(\n",
    "        None, description=\"The organization responsible for producing the dataset.\"\n",
    "    )\n",
    "    data_type: Optional[str] = Field(\n",
    "        None, description=\"The type of data represented by the dataset.\"\n",
    "    )\n",
    "    year: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"The year associated with the dataset, if explicitly mentioned.\",\n",
    "    )\n",
    "    valid: bool = Field(\n",
    "        ..., description=\"True if the mention is valid, false otherwise.\"\n",
    "    )\n",
    "    invalid_reason: Optional[str] = Field(\n",
    "        None, description=\"Reason why the mention was invalid (if applicable).\"\n",
    "    )\n",
    "    sent: Optional[str] = Field(\n",
    "        None, description=\"The exact sentence where the dataset is mentioned.\"\n",
    "    )\n",
    "    # entities: Optional[EmpiricalMention] = Field(None, description=\"Additional empirical context for the dataset.\")\n",
    "\n",
    "    # Validator to ensure valid and invalid_reason consistency\n",
    "    @model_validator(mode=\"after\")\n",
    "    def check_validity(cls, instance):\n",
    "        if not instance.valid and not instance.invalid_reason:\n",
    "            raise ValueError(\"If 'valid' is False, 'invalid_reason' must be provided.\")\n",
    "        return instance\n",
    "\n",
    "\n",
    "class JudgeDatasetGroup(BaseModel):\n",
    "    mentioned_in: Optional[str] = Field(\n",
    "        None, description=\"The exact text excerpt where the dataset is mentioned.\"\n",
    "    )\n",
    "    datasets: List[JudgeDatasetEntry] = Field(\n",
    "        ..., description=\"A list of validated datasets mentioned in the paper.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class JudgeResponseFormat(BaseModel):\n",
    "    page_number: int = Field(..., description=\"The page number in the document.\")\n",
    "    dataset_used: bool = Field(\n",
    "        ...,\n",
    "        description=\"Flag indicating whether a valid dataset is mentioned in the page.\",\n",
    "    )\n",
    "    data_mentions: List[JudgeDatasetGroup] = Field(\n",
    "        ...,\n",
    "        description=\"A list of structured dataset information mentioned in the paper.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:09.967506Z",
     "iopub.status.busy": "2025-02-20T06:55:09.967053Z",
     "iopub.status.idle": "2025-02-20T06:55:09.987177Z",
     "shell.execute_reply": "2025-02-20T06:55:09.985981Z",
     "shell.execute_reply.started": "2025-02-20T06:55:09.967468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# judge prompt\n",
    "JUDGE_PROMPT = \"\"\"You are an expert in dataset validation. Your task is to assess whether each dataset mention is **valid, invalid, or requires clarification**, ensuring correctness and consistency based on the dataset's **empirical context**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Dataset Validation Criteria**\n",
    "A dataset is **valid** if:\n",
    "1. **It is structured**—collected systematically for research, policy, or administrative purposes.\n",
    "2. **It is reproducible**—meaning it consists of collected records rather than being derived purely from computations or models.\n",
    "\n",
    "**Always Valid Datasets:**\n",
    "- Government statistical and geospatial datasets (e.g., census, official land records).  \n",
    "- Official surveys, administrative records, economic transaction data, and scientific research datasets.  \n",
    "\n",
    "**Invalid Datasets:**\n",
    "Set as invalid all `\"raw_name\"` that belong under the following classes.\n",
    "- Derived indicators or computational constructs (e.g., \"wealth score\", \"mine dummy\", \"district total production\").  \n",
    "- Standalone statistical metrics without a clear underlying dataset (e.g., \"average income growth rate\" without source data).  \n",
    "- General organizations, reports, or methodologies (e.g., \"World Bank\", \"UNDP Report\", \"machine learning model\").  \n",
    "\n",
    "**Uncertain Cases:**\n",
    "- If a dataset is **vaguely named but potentially valid**, set it as valid but return: `\"Potentially valid—needs dataset name confirmation.\"`  \n",
    "- If a dataset reference is **too generic** (e.g., `\"time-varying data on production\"`), set it as valid but return: `\"Needs clarification—dataset name is too generic.\"`  \n",
    "\n",
    "---\n",
    "\n",
    "### **Key Validation Rules**\n",
    "1. **Consistency Check:**  \n",
    "   - If a `\"raw_name\"` has been marked **valid earlier**, it **must remain valid** unless its meaning significantly differs in a new context.\n",
    "\n",
    "2. **Context-Aware Inference:**  \n",
    "   - If certain details are missing such as the **Year**, **Producer**, or **Data Type**, try to extract them from the `mentioned_in` field if available and correctly relate to the data.\n",
    "\n",
    "3. **Data Type Classification (Flexible & Adaptive):**  \n",
    "   - Infer the most appropriate `\"data_type\"` dynamically from context.  \n",
    "   - Possible types: **Surveys, geospatial data, administrative records, financial reports, research datasets, climate observations, etc.**  \n",
    "   - If **no predefined category fits**, create a **new `\"data_type\"` that best describes the dataset.**  \n",
    "\n",
    "4. **Producer Identification:**  \n",
    "   - If the **producer (organization/institution) is explicitly mentioned**, extract it.  \n",
    "   - If not mentioned, **do not infer—set `\"producer\": None\"` instead.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **JudgeResponseFormat Schema**\n",
    "Each dataset assessment must conform strictly to the JudgeResponseFormat schema.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:09.988965Z",
     "iopub.status.busy": "2025-02-20T06:55:09.988487Z",
     "iopub.status.idle": "2025-02-20T06:55:10.009520Z",
     "shell.execute_reply": "2025-02-20T06:55:10.008298Z",
     "shell.execute_reply.started": "2025-02-20T06:55:09.988929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory for batch files & results\n",
    "JUDGE_BATCH_DIR = \"./openai-batchfiles/judge-batches\"  # Directory for batch files\n",
    "JUDGE_OUTPUT_DIR = \"./extraction_outputs/judge\"  # Directory for OpenAI API responses\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "# Ensure output folders exist\n",
    "os.makedirs(JUDGE_BATCH_DIR, exist_ok=True)\n",
    "os.makedirs(JUDGE_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:10.011008Z",
     "iopub.status.busy": "2025-02-20T06:55:10.010711Z",
     "iopub.status.idle": "2025-02-20T06:55:10.023171Z",
     "shell.execute_reply": "2025-02-20T06:55:10.022101Z",
     "shell.execute_reply.started": "2025-02-20T06:55:10.010984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extracted_outputs_to_batch(extraction_fname, prompt, response_format):\n",
    "    \"\"\"Processes a single extraction file into a judge batch file.\"\"\"\n",
    "\n",
    "    file_basename = os.path.basename(extraction_fname).replace(\".json\", \"\")\n",
    "    batch_fname = os.path.join(JUDGE_BATCH_DIR, f\"judge-batch-{file_basename}.jsonl\")\n",
    "\n",
    "    if os.path.exists(batch_fname):\n",
    "        print(f\"Batch file {batch_fname} already exists. Skipping.\")\n",
    "        return batch_fname  # Skip if already processed\n",
    "\n",
    "    with open(extraction_fname, \"r\") as f:\n",
    "        extraction_data = json.load(f)\n",
    "\n",
    "    for page_data in extraction_data[\"pages\"]:\n",
    "        page_num = page_data.get(\"page\")\n",
    "        data = page_data.get(\"data_mentions\")\n",
    "\n",
    "        if not data:\n",
    "            continue\n",
    "\n",
    "        custom_id = f\"{file_basename}-page-{page_num}\"\n",
    "        batch_entry = dict(\n",
    "            custom_id=custom_id,\n",
    "            method=\"POST\",\n",
    "            url=\"/v1/chat/completions\",\n",
    "            body=build_payload(json.dumps(data), prompt, response_format),\n",
    "        )\n",
    "\n",
    "        with open(batch_fname, \"a+\") as f:\n",
    "            f.write(json.dumps(batch_entry) + \"\\n\")\n",
    "\n",
    "    print(f\"Created batch file: {batch_fname}\")\n",
    "    return batch_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:10.024754Z",
     "iopub.status.busy": "2025-02-20T06:55:10.024357Z",
     "iopub.status.idle": "2025-02-20T06:55:10.044947Z",
     "shell.execute_reply": "2025-02-20T06:55:10.043864Z",
     "shell.execute_reply.started": "2025-02-20T06:55:10.024724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EXTRACTION_DIRECTORY = \"./extraction_outputs\"\n",
    "EXTRACTION_FILES = glob.glob(EXTRACTION_DIRECTORY + \"/extraction/*.json\")\n",
    "judge_prompt = JUDGE_PROMPT\n",
    "judge_response_format = JudgeResponseFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:10.046330Z",
     "iopub.status.busy": "2025-02-20T06:55:10.045996Z",
     "iopub.status.idle": "2025-02-20T06:55:10.067258Z",
     "shell.execute_reply": "2025-02-20T06:55:10.066187Z",
     "shell.execute_reply.started": "2025-02-20T06:55:10.046271Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EXTRACTION_FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:10.069005Z",
     "iopub.status.busy": "2025-02-20T06:55:10.068688Z",
     "iopub.status.idle": "2025-02-20T06:55:10.172916Z",
     "shell.execute_reply": "2025-02-20T06:55:10.171743Z",
     "shell.execute_reply.started": "2025-02-20T06:55:10.068976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# loop through each PDF file and process it into a batch\n",
    "for json_fname in EXTRACTION_FILES:\n",
    "    _ = extracted_outputs_to_batch(json_fname, judge_prompt, judge_response_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:10.214061Z",
     "iopub.status.busy": "2025-02-20T06:55:10.213792Z",
     "iopub.status.idle": "2025-02-20T06:55:10.227014Z",
     "shell.execute_reply": "2025-02-20T06:55:10.225713Z",
     "shell.execute_reply.started": "2025-02-20T06:55:10.214036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "merged_judge_batches = consolidate_batches(\n",
    "    batch_dir=JUDGE_BATCH_DIR, batch_size=10, process=\"judge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:10.228646Z",
     "iopub.status.busy": "2025-02-20T06:55:10.228225Z",
     "iopub.status.idle": "2025-02-20T06:55:10.235984Z",
     "shell.execute_reply": "2025-02-20T06:55:10.234706Z",
     "shell.execute_reply.started": "2025-02-20T06:55:10.228604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "merged_judge_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:10.237591Z",
     "iopub.status.busy": "2025-02-20T06:55:10.237182Z",
     "iopub.status.idle": "2025-02-20T06:55:10.254198Z",
     "shell.execute_reply": "2025-02-20T06:55:10.253043Z",
     "shell.execute_reply.started": "2025-02-20T06:55:10.237552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "openai_judge_batches = submit_batches_to_openai(merged_judge_batches)  # submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:10.255788Z",
     "iopub.status.busy": "2025-02-20T06:55:10.255404Z",
     "iopub.status.idle": "2025-02-20T06:55:10.271784Z",
     "shell.execute_reply": "2025-02-20T06:55:10.270653Z",
     "shell.execute_reply.started": "2025-02-20T06:55:10.255737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for judge_batch in openai_judge_batches:\n",
    "    print(judge_batch.id, client.batches.retrieve(judge_batch.id).status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:10.273839Z",
     "iopub.status.busy": "2025-02-20T06:55:10.273360Z",
     "iopub.status.idle": "2025-02-20T06:55:13.248181Z",
     "shell.execute_reply": "2025-02-20T06:55:13.247045Z",
     "shell.execute_reply.started": "2025-02-20T06:55:10.273796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for demo purposes, the following batch_ids are completed and ready for download\n",
    "judge_batch_ids = [\n",
    "    \"batch_67b5eccdd0788190b90d2eda5a0eb580\",\n",
    "    \"batch_67b5eccbca848190bf0d16ae8a8fa7ea\",\n",
    "]\n",
    "_ = retrieve_batch_results(judge_batch_ids, process=\"judge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.249605Z",
     "iopub.status.busy": "2025-02-20T06:55:13.249251Z",
     "iopub.status.idle": "2025-02-20T06:55:13.256583Z",
     "shell.execute_reply": "2025-02-20T06:55:13.255386Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.249565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_files = glob.glob(\"./batches/judge/results-*.jsonl\")\n",
    "judge_payload = load_and_save_outputs(batch_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.257686Z",
     "iopub.status.busy": "2025-02-20T06:55:13.257383Z",
     "iopub.status.idle": "2025-02-20T06:55:13.293040Z",
     "shell.execute_reply": "2025-02-20T06:55:13.291531Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.257650Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "judge_payload[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.294747Z",
     "iopub.status.busy": "2025-02-20T06:55:13.294381Z",
     "iopub.status.idle": "2025-02-20T06:55:13.305693Z",
     "shell.execute_reply": "2025-02-20T06:55:13.304542Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.294717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def map_judge_output(judge_payload, judge_path):\n",
    "    os.makedirs(judge_path, exist_ok=True)\n",
    "\n",
    "    for res in judge_payload:\n",
    "        fname_origin = res[\"custom_id\"].split(\"-page-\")[0]\n",
    "        page_number = int(res[\"custom_id\"].split(\"-page-\")[1])\n",
    "        content = json.loads(\n",
    "            res[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        )\n",
    "\n",
    "        extraction_resfname = os.path.join(judge_path, f\"{fname_origin}.json\")\n",
    "\n",
    "        if content.get(\"data_mentions\"):\n",
    "            # Construct the page entry\n",
    "            page_entry = {\n",
    "                \"page\": page_number,\n",
    "                \"dataset_used\": bool(content.get(\"data_mentions\")),\n",
    "                \"data_mentions\": content[\"data_mentions\"],\n",
    "            }\n",
    "\n",
    "            # Read existing data\n",
    "            if os.path.exists(extraction_resfname):\n",
    "                with open(extraction_resfname, \"r\", encoding=\"utf-8\") as f:\n",
    "                    try:\n",
    "                        existing_data = json.load(f)\n",
    "                    except json.JSONDecodeError:\n",
    "                        existing_data = {\n",
    "                            \"source\": fname_origin,\n",
    "                            \"pages\": [],\n",
    "                        }  # Handle empty or corrupted file\n",
    "            else:\n",
    "                existing_data = {\"source\": fname_origin, \"pages\": []}\n",
    "\n",
    "            # Ensure the existing structure is correct\n",
    "            if \"pages\" not in existing_data:\n",
    "                existing_data[\"pages\"] = []\n",
    "\n",
    "            # Append new page entry\n",
    "            existing_data[\"pages\"].append(page_entry)\n",
    "\n",
    "            # Write back to file\n",
    "            with open(extraction_resfname, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(existing_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.307220Z",
     "iopub.status.busy": "2025-02-20T06:55:13.306798Z",
     "iopub.status.idle": "2025-02-20T06:55:13.346786Z",
     "shell.execute_reply": "2025-02-20T06:55:13.345716Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.307185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "judge_path = \"./extraction_outputs/judge\"\n",
    "_ = map_judge_output(judge_payload, judge_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autonomous Reasoning Agent\n",
    "\n",
    "Once the information is validated by the LLM, we will use the autonomous reasoning agent to further refine and validate the extracted data. The reasoning agent will follow a structured prompt to ensure the accuracy and relevance of the dataset mentions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.347961Z",
     "iopub.status.busy": "2025-02-20T06:55:13.347713Z",
     "iopub.status.idle": "2025-02-20T06:55:13.353528Z",
     "shell.execute_reply": "2025-02-20T06:55:13.352228Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.347939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "THINKING_PROMPT = \"\"\"Your task is to review a structured user input that may mention a dataset in a text. Please take your time.\n",
    "\n",
    "Carefully analyze what the text in the `mentioned_in` field explicitly means and in what context the `raw_name` is discussed. Never infer, imply, or assume, so you must exclusively rely on the text as facts. If there are multiple datasets, do the assessment individually.\n",
    "\n",
    "Plan a strategy to ensure you can maximize the chances of correctly judging and classifying whether the provided input:\n",
    "- Clearly, the `raw_name` falls under the concept of a data/dataset and not by extension or implicitly.\n",
    "- Whether the raw_name is actually in the `mentioned_in`.\n",
    "- Whether the harmonized_name (if present) is actually in the `mentioned_in`. If not found, remove it from the output.\n",
    "- The `raw_name` is `properly_named` (e.g., DHS, LSMS, etc.), `descriptive_but_unnamed` (administrative school records in Ghana for 2020) , or `vague_generic` (a survey data). Any of these are valid data mentions. To be sure, elaborate how you interpret these classes and use that for classifying.\n",
    "- The context concerning usage of the dataset is mentioned: is it `primary`, `supporting`, or `background`.\n",
    "\n",
    "Then, write down your strategy.\n",
    "\n",
    "After you write down your strategy, synthesize it to develop a rubric of what qualifies as a dataset, which you must use to base your judgment.\n",
    "\n",
    "Incorporate a devil's advocate review as part of your strategy. If the review shows inconsistency, update accordingly. Do not reason based on assumption, inference, or implicit thinking.  Relationships do not count as a dataset; for example, the producer is not a dataset.\n",
    "\n",
    "Execute the strategy, **step by step**, and write an analysis of how you interpret the `raw_name` in the context of the `mentioned_in`.\n",
    "\n",
    "If your analysis results in the `raw_name` being a dataset, set the `valid` field to `true`, otherwise, set it to `false`. In both cases, return the result of your analysis focusing on the `raw_name` in the `reason` field. If it is invalid, set the `specificity` and `context` to null.\n",
    "\n",
    "ALWAYS WRITE A DEVIL'S ADVOCATE REVIEW AFTER THE ANALYSIS BEFORE CONCLUDING.\n",
    "\n",
    "After you write your analysis, your output must repeat the input with the `specificity`, `context`, `valid` and `invalid_reason` values replaced accordingly in the same level as the corresponding `raw_name`. IMPORTANT: the final output must be between these tags <OUTPUTDATA>```json<the output must be here>```</OUTPUTDATA>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.354890Z",
     "iopub.status.busy": "2025-02-20T06:55:13.354569Z",
     "iopub.status.idle": "2025-02-20T06:55:13.376234Z",
     "shell.execute_reply": "2025-02-20T06:55:13.374898Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.354864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# we are only interested in valid mentions of data from the judge llm\n",
    "def filter_valid_mentions(validated_input):\n",
    "    # Filter out invalid datasets before passing to LLM\n",
    "    filtered_mentions = []\n",
    "    for page in validated_input[\"pages\"]:\n",
    "        for mention in page.get(\"data_mentions\", []):\n",
    "            valid_datasets = [\n",
    "                dataset\n",
    "                for dataset in mention[\"datasets\"]\n",
    "                if dataset.get(\"valid\", False)\n",
    "            ]\n",
    "\n",
    "            if valid_datasets:  # Only keep mentions with at least one valid dataset\n",
    "                filtered_mentions.append(\n",
    "                    {\n",
    "                        \"mentioned_in\": mention[\"mentioned_in\"],\n",
    "                        \"datasets\": valid_datasets,\n",
    "                        \"page\": page[\"page\"],\n",
    "                        \"dataset_used\": page[\"dataset_used\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    input_data = {\n",
    "        \"source\": validated_input.get(\"source\"),\n",
    "        \"data_mentions\": filtered_mentions,\n",
    "    }\n",
    "\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.377714Z",
     "iopub.status.busy": "2025-02-20T06:55:13.377433Z",
     "iopub.status.idle": "2025-02-20T06:55:13.393692Z",
     "shell.execute_reply": "2025-02-20T06:55:13.392377Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.377689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_input_data(data):\n",
    "    for mention in data.get(\"data_mentions\", []):\n",
    "        for ds in mention.get(\"datasets\", []):\n",
    "            # Replace string \"None\" with actual None\n",
    "            if ds.get(\"producer\") == \"None\":\n",
    "                ds[\"producer\"] = None\n",
    "\n",
    "            # Remove unwanted keys\n",
    "            keys_to_remove = [\n",
    "                \"sent\",\n",
    "                \"specificity\",\n",
    "                \"context\",\n",
    "                \"relevance\",\n",
    "                \"data_type\",\n",
    "                \"valid\",\n",
    "                \"invalid_reason\",\n",
    "            ]\n",
    "            for key in keys_to_remove:\n",
    "                ds.pop(key, None)  # `None` as default to avoid KeyError\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.395161Z",
     "iopub.status.busy": "2025-02-20T06:55:13.394887Z",
     "iopub.status.idle": "2025-02-20T06:55:13.412926Z",
     "shell.execute_reply": "2025-02-20T06:55:13.411567Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.395136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory for batch files & results\n",
    "REASONING_BATCH_DIR = (\n",
    "    \"./openai-batchfiles/reasoning-batches\"  # Directory for batch files\n",
    ")\n",
    "REASONING_OUTPUT_DIR = (\n",
    "    \"./extraction_outputs/reasoning\"  # Directory for OpenAI API responses\n",
    ")\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "# Ensure output folders exist\n",
    "os.makedirs(REASONING_BATCH_DIR, exist_ok=True)\n",
    "os.makedirs(REASONING_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.414463Z",
     "iopub.status.busy": "2025-02-20T06:55:13.414110Z",
     "iopub.status.idle": "2025-02-20T06:55:13.431037Z",
     "shell.execute_reply": "2025-02-20T06:55:13.429913Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.414432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from hashlib import md5\n",
    "\n",
    "\n",
    "def judge_outputs_to_batch(judge_fname, prompt):\n",
    "    \"\"\"Processes a single judge file into a reasoning batch file.\"\"\"\n",
    "\n",
    "    file_basename = os.path.basename(judge_fname).replace(\".json\", \"\")\n",
    "    batch_fname = os.path.join(\n",
    "        REASONING_BATCH_DIR, f\"reasoning-batch-{file_basename}.jsonl\"\n",
    "    )\n",
    "\n",
    "    if os.path.exists(batch_fname):\n",
    "        print(f\"Batch file {batch_fname} already exists. Skipping.\")\n",
    "        return batch_fname  # Skip if already processed\n",
    "\n",
    "    with open(judge_fname, \"r\") as f:\n",
    "        judge_data = json.load(f)\n",
    "\n",
    "    filtered_data = filter_valid_mentions(judge_data)\n",
    "    prepared_data = prepare_input_data(filtered_data)\n",
    "\n",
    "    for page_data in prepared_data[\"data_mentions\"]:\n",
    "        mention_hash = page_data.get(\"mentioned_in\")\n",
    "        if not mention_hash:\n",
    "            continue\n",
    "        mhash = md5(mention_hash.encode()).hexdigest()[:8]\n",
    "        custom_id = f\"{file_basename}_{mhash}-pg-{page_data['page']}\"\n",
    "        batch_entry = dict(\n",
    "            custom_id=custom_id,\n",
    "            method=\"POST\",\n",
    "            url=\"/v1/chat/completions\",\n",
    "            body=build_payload(json.dumps(page_data), prompt),\n",
    "        )\n",
    "\n",
    "        with open(batch_fname, \"a+\") as f:\n",
    "            f.write(json.dumps(batch_entry) + \"\\n\")\n",
    "\n",
    "    print(f\"Created batch file: {batch_fname}\")\n",
    "    return batch_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.432596Z",
     "iopub.status.busy": "2025-02-20T06:55:13.432314Z",
     "iopub.status.idle": "2025-02-20T06:55:13.455690Z",
     "shell.execute_reply": "2025-02-20T06:55:13.454196Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.432563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EXTRACTION_DIRECTORY = \"./extraction_outputs\"\n",
    "JUDGE_FILES = glob.glob(EXTRACTION_DIRECTORY + \"/judge/*.json\")\n",
    "reasoning_prompt = THINKING_PROMPT\n",
    "# loop through each PDF file and process it into a batch\n",
    "for json_fname in JUDGE_FILES:\n",
    "    _ = judge_outputs_to_batch(json_fname, reasoning_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.466940Z",
     "iopub.status.busy": "2025-02-20T06:55:13.466645Z",
     "iopub.status.idle": "2025-02-20T06:55:13.484973Z",
     "shell.execute_reply": "2025-02-20T06:55:13.483643Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.466914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "openai_reasoning_batches = consolidate_batches(\n",
    "    batch_dir=REASONING_BATCH_DIR, batch_size=15, process=\"reasoning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:13.486715Z",
     "iopub.status.busy": "2025-02-20T06:55:13.486342Z",
     "iopub.status.idle": "2025-02-20T06:55:17.433093Z",
     "shell.execute_reply": "2025-02-20T06:55:17.431681Z",
     "shell.execute_reply.started": "2025-02-20T06:55:13.486687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "openai_reasoning_batches = submit_batches_to_openai(openai_reasoning_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reasoning_batch in openai_reasoning_batches:\n",
    "    print(client.batches.retrieve(reasoning_batch.id).status, reasoning_batch.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:17.435135Z",
     "iopub.status.busy": "2025-02-20T06:55:17.434704Z",
     "iopub.status.idle": "2025-02-20T06:55:17.439980Z",
     "shell.execute_reply": "2025-02-20T06:55:17.438688Z",
     "shell.execute_reply.started": "2025-02-20T06:55:17.435092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# openai_reasoning_batches = [batch.id for batch in openai_reasoning_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T06:55:17.788150Z",
     "iopub.status.busy": "2025-02-20T06:55:17.787864Z",
     "iopub.status.idle": "2025-02-20T06:55:18.746927Z",
     "shell.execute_reply": "2025-02-20T06:55:18.745851Z",
     "shell.execute_reply.started": "2025-02-20T06:55:17.788124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for demo purposes, the following batch_ids are completed and ready for download\n",
    "reasoning_batch_ids = [\n",
    "    \"batch_67b6c639468c8190b87726743431e76f\",\n",
    "    \"batch_67b6c63b48848190be8cfc7fa018300c\",\n",
    "]\n",
    "_ = retrieve_batch_results(reasoning_batch_ids, process=\"reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T07:06:50.153393Z",
     "iopub.status.busy": "2025-02-20T07:06:50.153007Z",
     "iopub.status.idle": "2025-02-20T07:06:50.162578Z",
     "shell.execute_reply": "2025-02-20T07:06:50.161073Z",
     "shell.execute_reply.started": "2025-02-20T07:06:50.153359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_files_reasoning = glob.glob(\"./batches/reasoning/results-*.jsonl\")\n",
    "reasoning_payload = load_and_save_outputs(batch_files_reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T07:31:51.890587Z",
     "iopub.status.busy": "2025-02-20T07:31:51.890105Z",
     "iopub.status.idle": "2025-02-20T07:31:51.903289Z",
     "shell.execute_reply": "2025-02-20T07:31:51.901933Z",
     "shell.execute_reply.started": "2025-02-20T07:31:51.890546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def map_reasoning_output(reasoning_payload, reasoning_path):\n",
    "    os.makedirs(reasoning_path, exist_ok=True)\n",
    "\n",
    "    for res in reasoning_payload:\n",
    "        fname_origin = res[\"custom_id\"].split(\"_\")[0]\n",
    "        content = res[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        reasoning_fname = os.path.join(reasoning_path, f\"{fname_origin}.json\")\n",
    "\n",
    "        content = content[content.index(\"```json\") + len(\"```json\") :]\n",
    "        content = content[: content.index(\"```\")]\n",
    "\n",
    "        if \"<outputdata>\" in content.lower() and \"</outputdata>\" in content.lower():\n",
    "            soup = BeautifulSoup(content, \"html.parser\")\n",
    "            content = soup.find(\"outputdata\").text\n",
    "\n",
    "        content = json.loads(content)\n",
    "        # Construct the page entry\n",
    "        filtered_data = []\n",
    "        filtered_data.append(\n",
    "            {\n",
    "                \"mentioned_in\": content[\"mentioned_in\"],\n",
    "                \"page\": content[\"page\"],\n",
    "                \"dataset_used\": content[\"dataset_used\"],\n",
    "                \"datasets\": [\n",
    "                    dataset\n",
    "                    for dataset in content.get(\"datasets\")\n",
    "                    if dataset.get(\"valid\", False)\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        page_entry = {\n",
    "            \"data_mentions\": filtered_data  # we keep only valid: true entries\n",
    "        }\n",
    "\n",
    "        if os.path.exists(reasoning_fname):\n",
    "            with open(reasoning_fname, \"r\", encoding=\"utf-8\") as f:\n",
    "                try:\n",
    "                    existing_data = json.load(f)\n",
    "                except json.JSONDecodeError:\n",
    "                    existing_data = {\n",
    "                        \"source\": fname_origin,\n",
    "                        \"pages\": [],\n",
    "                    }  # Handle empty or corrupted file\n",
    "        else:\n",
    "            existing_data = {\"source\": fname_origin, \"pages\": []}\n",
    "\n",
    "        # Ensure the existing structure is correct\n",
    "        if \"pages\" not in existing_data:\n",
    "            existing_data[\"pages\"] = []\n",
    "\n",
    "        # Append new page entry\n",
    "        existing_data[\"pages\"].append(page_entry)\n",
    "\n",
    "        # Write back to file\n",
    "        with open(reasoning_fname, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(existing_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T07:31:53.151501Z",
     "iopub.status.busy": "2025-02-20T07:31:53.151129Z",
     "iopub.status.idle": "2025-02-20T07:31:53.182371Z",
     "shell.execute_reply": "2025-02-20T07:31:53.181113Z",
     "shell.execute_reply.started": "2025-02-20T07:31:53.151473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "reasoning_path = \"./extraction_outputs/reasoning\"\n",
    "_ = map_reasoning_output(reasoning_payload, reasoning_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T07:31:54.419188Z",
     "iopub.status.busy": "2025-02-20T07:31:54.418636Z",
     "iopub.status.idle": "2025-02-20T07:31:54.442862Z",
     "shell.execute_reply": "2025-02-20T07:31:54.441419Z",
     "shell.execute_reply.started": "2025-02-20T07:31:54.419144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inspect_json(\n",
    "    \"./extraction_outputs/reasoning/The-local-socioeconomic-effects-of-gold-mining-evidence-from-Ghana.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now you can make your fine-tuning dataset. This notebook has walked you through a comprehensive batch processing implementation for data labeling of climate change-related documents. By leveraging various tools and libraries, we've automated and streamlined the data labeling process.\n",
    "\n",
    "For making your fine-tuning dataset, you can check [this notebook](generate-finetuning-simpleschema.ipynb) to learn more."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6700722,
     "sourceId": 10796664,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ai4data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
